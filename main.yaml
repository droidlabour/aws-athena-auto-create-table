AWSTemplateFormatVersion: 2010-09-09

Description: Amazon Athena

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
    - Label:
        default: Athena Settings
      Parameters:
      - InputBucketName
      - InputBucketPath
      - AthenaDBName
      - TableName
      - TableColumns

Parameters:
  InputBucketName:
    Type: String
    Description: Input S3 Bucket Name where files will be uploaded for Athena
  InputBucketPath:
    Type: String
    Description: Input S3 Bucket Path where files will be uploaded for Athena
  TableColumns:
    Type: String
    Description: 'The columns and their types in the format: col_name_1 data_type_1,  col_name_2 data_type_2, col_name_3 data_type_3, .... col_name_n data_type_n'
    Default: display-name string, last-logon-date string, account-creation-date string, username string, first-name string, last-name string, contractor-employee string, astellas-userid string, manager string, department string, company string, astellas-office string, email string, account-status string, account-location string, groups string
  AthenaDBName:
    Type: String
    AllowedPattern: ^[a-z]*$
    Description: Athena Database name, will be created if it does not exist
  TableName:
    Type: String
    AllowedPattern: ^[a-z0-9-_]+$
    Description: Athena table name

Resources:
  InputBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref InputBucketName
  OutputBucket:
    Type: AWS::S3::Bucket
  CreateTable:
    Type: AWS::CloudFormation::CustomResource
    Properties:
      ServiceToken: !GetAtt CreateTableFunction.Arn
      AthenaDBName: !Ref AthenaDBName
      TableName: !Ref TableName
      Columns: !Ref TableColumns
      SourceUri: !Sub s3://${InputBucket}/${InputBucketPath}/
      OutputLocation: !Sub s3://${OutputBucket}/
  CreateTableFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          import json
          import traceback
          from time import sleep
          import boto3
          import cfnresponse

          client = boto3.client('athena')
          create_table_tpl = """
          CREATE EXTERNAL TABLE IF NOT EXISTS
            {db_name}.{table_name} {columns}
            ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
            WITH SERDEPROPERTIES ('serialization.format' = ',', 'field.delim' = ',')
            LOCATION '{location}'
            TBLPROPERTIES ('skip.header.line.count'='1');
          """
          create_view_tpl = """
          CREATE OR REPLACE VIEW "{view_name}" AS
            SELECT *,
            Coalesce(
                {v1} '%Y-%m-%d %H:%i:%s')),
                {v1} '%Y/%m/%d %H:%i:%s')),
                {v1} '%d %M %Y %H:%i:%s')),
                {v1} '%d/%m/%Y %H:%i:%s')),
                {v1} '%d-%m-%Y %H:%i:%s')),
                {v1} '%Y-%m-%d')),
                {v1} '%Y/%m/%d')),
                {v1} '%d %M %Y')),
                {v1} '%Y-%m-%d %H:%i:%s %p')),
                {v1} '%Y/%m/%d %H:%i:%s %p')),
                {v1} '%d %M %Y %H:%i:%s %p')),
                {v1} '%d/%m/%Y %H:%i:%s %p')),
                {v1} '%d-%m-%Y %H:%i:%s %p')),
                {v1} '%Y-%m-%d %p')),
                {v1} '%Y/%m/%d %p')),
                {v1} '%d %M %Y %p')),
                {v1} '%c/%d/%Y %l:%i:%s %p')),
                {v1} '%c-%d-%Y %l:%i:%s %p'))
            )as "account-creation-date-new",
            Coalesce(
                {v2} '%Y-%m-%d %H:%i:%s')),
                {v2} '%Y/%m/%d %H:%i:%s')),
                {v2} '%d %M %Y %H:%i:%s')),
                {v2} '%d/%m/%Y %H:%i:%s')),
                {v2} '%d-%m-%Y %H:%i:%s')),
                {v2} '%Y-%m-%d')),
                {v2} '%Y/%m/%d')),
                {v2} '%d %M %Y')),
                {v2} '%Y-%m-%d %H:%i:%s %p')),
                {v2} '%Y/%m/%d %H:%i:%s %p')),
                {v2} '%d %M %Y %H:%i:%s %p')),
                {v2} '%d/%m/%Y %H:%i:%s %p')),
                {v2} '%d-%m-%Y %H:%i:%s %p')),
                {v2} '%Y-%m-%d %p')),
                {v2} '%Y/%m/%d %p')),
                {v2} '%d %M %Y %p')),
                {v2} '%c/%d/%Y %l:%i:%s %p')),
                {v2} '%c-%d-%Y %l:%i:%s %p'))
            )as "last-logon-date-new"
            FROM "{table_name}";
          """


          def query_status(qid):
              return client.get_query_execution(QueryExecutionId=qid)['QueryExecution']['Status']['State']


          def wait_query_to_finish(qid):
              while query_status(qid) in ['QUEUED', 'RUNNING']:
                  print("Waiting query id to finish {}".format(qid))
                  sleep(5)
              print("query id finished {}".format(qid))


          def run_query(query, payload):
              print("Running query: {}".format(query))
              qid = client.start_query_execution(
                  QueryString=query,
                  QueryExecutionContext={'Database': payload['AthenaDBName']},
                  ResultConfiguration={
                      'OutputLocation': payload['OutputLocation']
                  }
              )['QueryExecutionId']
              print("query id: {}".format(qid))
              return qid


          def esc_columns(d):
              x = d['Columns']
              y = x.split(',')
              z = []
              for i in y:
                  s = i.strip().split()
                  field = '`' + s[0] + '`'
                  type = s[1]
                  schema = ' '.join([field, type])
                  z.append(schema)
              return '(' + ', '.join(z) + ')'


          def lambda_handler(event, context):
              print(json.dumps(event))
              status = cfnresponse.FAILED
              cfn_input = event['ResourceProperties']
              query_dict = {
                  'db_name': cfn_input['AthenaDBName'],
                  'table_name': cfn_input['TableName'].replace('-', '_'),
                  'columns': esc_columns(cfn_input),
                  'location': cfn_input['SourceUri']
              }

              try:
                  if event['RequestType'] != 'Delete':
                      query = "CREATE DATABASE IF NOT EXISTS {};".format(query_dict['db_name'])
                      query_id = run_query(query, cfn_input)
                      wait_query_to_finish(query_id)

                      query = create_table_tpl.format(**query_dict)
                      query_id = run_query(query, cfn_input)
                      wait_query_to_finish(query_id)

                      query_dict['view_name'] = query_dict['table_name'] + '_view'
                      query_dict['v1'] = 'try(date_parse("account-creation-date",'
                      query_dict['v2'] = 'try(date_parse("last-logon-date",'
                      query = create_view_tpl.format(**query_dict)
                      query_id = run_query(query, cfn_input)
                      wait_query_to_finish(query_id)
                  status = cfnresponse.SUCCESS
              except Exception as e:
                  print(str(e))
                  traceback.print_exc()
              finally:
                  cfnresponse.send(event, context, status, {})
      Handler: index.lambda_handler
      FunctionName: Quicksight-Athena-Function
      Role: !GetAtt CreateTableRole.Arn
      Runtime: python2.7
      Timeout: 300
  CreateTableRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: /
      Policies:
      - PolicyName: CreateTablePolicy
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action: s3:*
            Resource: '*'
          - Effect: Allow
            Action: athena:*
            Resource: '*'
          - Effect: Allow
            Action: glue:*
            Resource: '*'
          - Effect: Allow
            Action:
            - logs:CreateLogGroup
            - logs:CreateLogStream
            - logs:PutLogEvents
            Resource: arn:aws:logs:*:*:*

Outputs:
  OutputLocation:
    Value: !Sub s3://${OutputBucket}/
